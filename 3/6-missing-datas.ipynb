{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4213ee7",
   "metadata": {},
   "source": [
    "I don't have the relevant dataset. It is only intended to provide information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee31943b-274e-4c28-bce6-155cb6f4c334"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "The datasets that data professionals use to solve problems typically contain missing values, which must be dealt with in order to achieve clean, useful data. This is particularly crucial in exploratory data analysis (EDA). In this activity, you will learn how to address missing data. \n",
    "\n",
    "You are a financial data consultant, and an investor has tasked your team with identifying new business opportunities. To help them decide which future companies to invest in, you will provide a list of current businesses valued at more than $1 billion. These are sometimes referred to as \"unicorns.\" Your client will use this information to learn about profitable businesses in general.\n",
    "\n",
    "The investor has asked you to provide them with the following data: \n",
    "- Companies in the `hardware` industry based in either `Beijing`, `San Francisco`, or `London` \n",
    "- Companies in the `artificial intelligence` industry based in `London`\n",
    "-  A list of the top 20 countries sorted by sum of company valuations in each country, excluding `United States`, `China`, `India`, and `United Kingdom`\n",
    "- A global valuation map of all countries with companies that joined the list after 2020\n",
    "- A global valuation map of all countries except `United States`, `China`, `India`, and `United Kingdom` (a separate map for Europe is also required)\n",
    "\n",
    "Your dataset includes a list of businesses and data points, such as the year they were founded; their industry; and their city, country, and continent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bb9630e-b940-4835-a389-d39def1fa848"
   },
   "source": [
    "## **Step 1: Imports** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aefe3c18"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc180686-4ae2-47ea-a292-3588ac60a820"
   },
   "source": [
    "Import the following relevant Python libraries:\n",
    "* `numpy`\n",
    "* `pandas`\n",
    "* `matplotlib.pyplot`\n",
    "* `plotly.express`\n",
    "* `seaborn`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8e7f1f2c-bbcc-4f3c-b927-b090ee8334c4"
   },
   "outputs": [],
   "source": [
    "# Import libraries and modules.\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, plotly.express as px, seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ecba4b6"
   },
   "source": [
    "### Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bd40d44-080f-4e49-b0c2-160dedc3c4df"
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO IMPORT YOUR DATA.\n",
    "df_companies = pd.read_csv(\"Unicorn_Companies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95bf39c9-d05c-4324-a40b-bc692607b61b"
   },
   "source": [
    "## **Step 2: Data exploration** \n",
    "\n",
    "Explore the dataset and answer questions that will guide your management of missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fe813508"
   },
   "source": [
    "### Display top rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26561614-8e9b-4840-8dbf-b50131ae5314",
    "tags": []
   },
   "source": [
    "Display the first 10 rows of the data to understand how the dataset is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad5210a5-7a64-4991-b004-de818cfaf506"
   },
   "outputs": [],
   "source": [
    "# Display the first 10 rows of the data.\n",
    "df_companies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55766062"
   },
   "source": [
    "### Statistical properties of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d423621-c14b-4987-a76d-feee76046144"
   },
   "source": [
    "Use methods and attributes of the dataframe to get information and descriptive statistics for the data, including its range, data types, mean values, and shape. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66809360"
   },
   "outputs": [],
   "source": [
    "# Get the shape of the dataset.\n",
    "df_companies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d85fc26"
   },
   "outputs": [],
   "source": [
    "# Get the data types and number of non-null values in the dataset.\n",
    "df_companies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfR-1rlkIXt-"
   },
   "outputs": [],
   "source": [
    "# Get descriptive statistics such as mean, standard deviation, and range of the numerical columns in the dataset.\n",
    "df_companies.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a885babf"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f46cb991"
   },
   "source": [
    "In order to answer the investor's questions, some data preprocessing steps are required. The first step is to add a new column to the dataframe containing just the year each company became a unicorn company. Call this new column `Year Joined`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15bfeecc"
   },
   "outputs": [],
   "source": [
    "# Create a new column \"Year Joined\" from \"Date Joined\".\n",
    "df_companies['Year_Joined'] = pd.to_datetime(df_companies['Date Joined']).dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64825929",
   "metadata": {
    "id": "5949c474"
   },
   "source": [
    "For each country, you want to calculate the sum of all valuations of companies from that country. However, in order to do this, you'll need to first prepare the data. Currently, the data in the `Valuation` column is a string that starts with a `$` and ends with a `B`. Because this column is not in a numeric datatype, pandas cannot perform mathematical operations on its values. The data in this column needs to be converted to a numeric datatype. \n",
    "\n",
    "In this step, define a function called `str_to_num()` that accepts as an argument:\n",
    "\n",
    "* `x`: a string in the format of the values contained in the `Valuation` column\n",
    "\n",
    "And returns:\n",
    "\n",
    "* `x`: an `int` of the number represented by the input string\n",
    "\n",
    "```\n",
    "Example:\n",
    "\n",
    " [IN]:  str_to_num('$4B')\n",
    "[OUT]:  4\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "To do this, use the string [`strip()`](https://docs.python.org/3/library/stdtypes.html#str.strip) method. This method is applied to a string. Its argument is a string that contains all the characters that you want to remove from the beginning and end of a given string&mdash;in any order. The specified characters will be removed until a valid character is encountered. This process is applied moving forward from the beginning of the string and also moving in reverse from the end of the string, thus removing unwanted beginning and trailing characters.\n",
    "\n",
    "```\n",
    "Example:\n",
    "\n",
    " [IN]:  my_string = '#....... Section 3.2.1 Issue #32 .......'\n",
    "        my_string = my_string.strip('.#! ')\n",
    "        print(my_string)\n",
    "\n",
    "[OUT]:  'Section 3.2.1 Issue #32'\n",
    "\n",
    "```\n",
    "\n",
    "Note that you must reassign the result back to a variable or else the change will not be permanent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1856c3c8-dd7e-4b0f-8e30-06e8ed6b9885"
   },
   "outputs": [],
   "source": [
    "# Define the `str_to_num()` function\n",
    "def str_to_num(value):\n",
    "    value = int(value.strip('$B'))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use this function to create a new column called `valuation_num` that represents the `Valuation` column as an integer value. To do this, use the series method [`apply()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html) to apply the `str_to_num()` function to the `Valuation` column.\n",
    "\n",
    "`apply()` is a method that can be used on a `DataFrame` or `Series` object. In this case, you're using it on the `Valuation` series. The method accepts a function as an argument and applies that function to each value in the series.\n",
    "\n",
    "```\n",
    "Example:\n",
    "\n",
    " [IN]: def square(x):\n",
    "           return x ** 2\n",
    "\n",
    "       my_series = pd.Series([0, 1, 2, 3])\n",
    "       my_series\n",
    "\n",
    "[OUT]: 0    0\n",
    "       1    1\n",
    "       2    2\n",
    "       3    3\n",
    "       dtype: int64\n",
    "\n",
    " [IN]: my_series = my_series.apply(square)\n",
    "       my_series\n",
    "\n",
    "[OUT]: 0    0\n",
    "       1    1\n",
    "       2    4\n",
    "       3    9\n",
    "       dtype: int64\n",
    "```\n",
    "\n",
    "Notice that the function passed as an argument to the `apply()` method does not have parentheses. It's just the function name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the `str_to_num()` function to the `Valuation` column\n",
    "# and assign the result back to a new column called `valuation_num`\n",
    "df_companies['Valuation_num'] = df_companies.Valuation.apply(str_to_num)\n",
    "df_companies[['Valuation', 'Valuation_num']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b27ef252"
   },
   "source": [
    "### Find missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bad4e67"
   },
   "source": [
    "The unicorn companies dataset is fairly clean, with few missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "939ded7d"
   },
   "outputs": [],
   "source": [
    "# Find the number of missing values in each column in this dataset.\n",
    "df_companies.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1e91864"
   },
   "source": [
    "### Review rows with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84a779e9"
   },
   "source": [
    "Before dealing with missing values, it's important to understand the nature of the missing value that is being filled. Display all rows with missing values from `df_companies`. To do this, perform the following three steps:\n",
    "\n",
    "1. Apply the `isna()` method to the `df_companies` dataframe as you did in the last step. Remember, this results in a dataframe of the same shape as `df_companies` where each value is `True` if its contents are `NaN` and a `False` if its contents are not `NaN`. Assign the results to a variable called `mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Apply the `isna()` method to the `df_companies` dataframe and assign back to `mask`\n",
    "mask = df_companies.isna()\n",
    "mask.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're not done yet. You still need to go from this dataframe of Boolean values to a dataframe of just the rows of `df_companies` that contain at least one `NaN` value. This means that you need a way to find the indices of the rows of the Boolean dataframe that contain at least one `True` value, then extract those indices from `df_companies`. \n",
    "\n",
    "You can do this using the [`any()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html) method for `DataFrame` objects. This method returns a Boolean `Series` indicating whether any value is `True` over a specified axis.\n",
    "\n",
    "```\n",
    "Example:\n",
    "\n",
    "df =     \n",
    "        A      B    C\n",
    "    0   0      a    10\n",
    "    1   False  0    1\n",
    "    2   NaN    NaN  NaN\n",
    "\n",
    "\n",
    " [IN]: df.any(axis=0)\n",
    "\n",
    "[OUT]: A    False\n",
    "       B     True\n",
    "       C     True\n",
    "       dtype: bool\n",
    "       \n",
    " [IN]: df.any(axis=1)\n",
    " \n",
    "[OUT]: 0     True\n",
    "       1     True\n",
    "       2    False\n",
    "       dtype: bool\n",
    "```\n",
    "\n",
    "Note that `0`, `False`, and `NaN` are considered `False` and anything else is considered `True`. \n",
    "\n",
    "2. Apply the `any()` method to the Boolean dataframe you created to make a Boolean series where each element in the series represents `True` if a row of the dataframe contains any `True` values and `False` if any row in the dataframe contains any `False` values. Assign the results back to `mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Apply the `any()` method to `mask` and assign the results back to `mask`\n",
    "mask = mask.any(axis=1)\n",
    "mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_companies.index)\n",
    "print(mask.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Because `mask` is now a series of Boolean values, you can use it as a Boolean mask. Apply the Boolean mask to the `df_companies` dataframe to return a filtered dataframe containing just the rows that contain a missing value. Assign the results to a variable called `df_missing_rows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Apply `mask` as a Boolean mask to `df_companies` and assign results to `df_missing_rows`\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "df_missing_rows = df_companies[mask]\n",
    "df_missing_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34021f9c"
   },
   "source": [
    "## Step 3: Model building\n",
    "\n",
    "Think of the model you are building as the completed dataset, which you will then use to inform the questions the investor has asked of you.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b7ff426"
   },
   "source": [
    "### Two ways to address missing values\n",
    "\n",
    "There are several ways to address missing values, which is critical in EDA. The two primary methods are removing them and imputing other values in their place. Choosing the proper method depends on the business problem and the value the solution will add or take away from the dataset.\n",
    "\n",
    "Here, you will try both. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the the effect of different actions, first store the original number of values in a variable. Create a variable called `count_total` that is an integer representing the total number of values in `df_companies`. For example, if the dataframe had 5 rows and 2 columns, then this number would be 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd63abb1"
   },
   "outputs": [],
   "source": [
    "# Store the total number of values in a variable called `count_total`\n",
    "count_total = df_companies.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remove all rows containing missing values and store the total number of remaining values in a variable called `count_dropna_rows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows containing missing values, determine number of remaining values \n",
    "count_dropna_rows = df_companies.dropna().size\n",
    "count_dropna_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remove all columns containing missing values and store the total number of cells in a variable called `count_dropna_columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns containing missing values, determine number of remaining values\n",
    "count_dropna_columns = df_companies.dropna(axis=1).size\n",
    "count_dropna_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, print the percentage of values removed by each method and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the percentage of values removed by dropping rows.\n",
    "drop_rows = ((count_total - count_dropna_rows) / count_total) * 100\n",
    "print(f'Percantage row {drop_rows:.3f}')\n",
    "\n",
    "# Print the percentage of values removed by dropping columns.\n",
    "drop_column = ((count_total - count_dropna_columns) / count_total) * 100\n",
    "print(f'Percantage column {drop_column:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83966996",
   "metadata": {
    "id": "mho08fTcTMSq"
   },
   "source": [
    "Now, practice the second method: imputation. Perform the following steps:\n",
    "\n",
    "1. Use the [`fillna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna) dataframe method to fill each missing value with the next non-NaN value in its column. Assign the results to a new dataframe called `df_companies_backfill`.\n",
    "\n",
    "```\n",
    "Example:\n",
    "\n",
    "df =     \n",
    "        A    B    C\n",
    "    0   5    a    NaN\n",
    "    1   10   NaN  False\n",
    "    2   NaN  c    True\n",
    "\n",
    " [IN]: df.fillna(method='backfill')\n",
    " \n",
    "[OUT]: \n",
    "        A    B    C\n",
    "    0   5    a    False\n",
    "    1   10   c    False\n",
    "    2   NaN  c    True\n",
    "\n",
    "```\n",
    "\n",
    "Notice that if there is a `NaN` value in the last row, it will not backfill because there is no subsequent value in the column to refer to. \n",
    "\n",
    "2. Show the rows that previously had missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fill missing values using the 'fillna()' method, back-filling\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "df_companies_backfill = df_companies.fillna(method='backfill')\n",
    "\n",
    "\n",
    "# 2. Show the rows that previously had missing values\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "df_companies_backfill.iloc[df_missing_rows.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f09108ed"
   },
   "source": [
    "## Step 4: Results and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54438f3c"
   },
   "source": [
    "### Companies in the `Hardware` Industry\n",
    "\n",
    "Your investor is interested in identifying unicorn companies in the `Hardware` industry in the following cities: `Beijing`, `San Francisco`, and `London`. They are also interested in companies in the `Artificial intelligence` industry in `London`. \n",
    "\n",
    "Write a selection statement that extracts the rows that meet these criteria. This task requires complex conditional logic. Break the process into the following parts.\n",
    "\n",
    "1. Create a mask to apply to the `df_companies` dataframe. The following logic is a pseudo-code representation of how this mask could be structured.\n",
    "\n",
    "```\n",
    "((Industry==Hardware) and (City==Beijing, San Francisco, or London)) \n",
    "OR  \n",
    "((Industry==Artificial intelligence) and (City==London))\n",
    "```\n",
    "\n",
    "You're familiar with how to create Boolean masks based on conditional logic in pandas. However, you might not know how to write a conditional statement that selects rows that have _any one of several possible values_ in a given column. In this case, this is the `(City==Beijing, San Francisco, or London)` part of the expression.\n",
    "\n",
    "For this type of construction, use the [`isin()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.isin.html#pandas.Series.isin) `Series` method. This method is applied to a pandas series and, for each value in the series, checks whether it is a member of whatever is passed as its argument.\n",
    "\n",
    "```\n",
    "Example:\n",
    "\n",
    " [IN]: my_series = pd.Series([0, 1, 2, 3])\n",
    "       my_series\n",
    "       \n",
    "[OUT]: 0    0\n",
    "       1    1\n",
    "       2    2\n",
    "       3    3\n",
    "       dtype: int64\n",
    "       \n",
    " [IN]: my_series.isin([1, 2])\n",
    "       \n",
    "[OUT]: 0    False\n",
    "       1     True\n",
    "       2     True\n",
    "       3    False\n",
    "       dtype: bool\n",
    "       \n",
    "```\n",
    "\n",
    "2. Apply the mask to the `df_companies` dataframe and assign the result to a new variable called `df_invest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTcm42EMIXuG"
   },
   "outputs": [],
   "source": [
    "# 1. Create a Boolean mask using conditional logic\n",
    "#We should use '|' and '&' on pandas\n",
    "cities = ['Beijing', 'San Francisco', 'London']\n",
    "mask = (\n",
    "    ((df_companies['Industry'] == 'Hardware') & df_companies['City'].isin(cities)) \n",
    "    |\n",
    "    ((df_companies['Industry'] == 'Artificial Intelligence') & (df_companies['City'] == 'London'))\n",
    ")\n",
    "\n",
    "# 2. Apply the mask to the `df_companies` dataframe and assign the results to `df_invest`\n",
    "df_invest = df_companies[mask]\n",
    "df_invest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5446b7aa"
   },
   "source": [
    "### List of countries by sum of valuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5606ef21"
   },
   "source": [
    "For each country, sum the valuations of all companies in that country, then sort the results in descending order by summed valuation. Assign the results to a variable called `national_valuations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "097dfa19"
   },
   "outputs": [],
   "source": [
    "# Group the data by`Country/Region`\n",
    "national_valuations = df_companies.groupby(['Country/Region'])['Valuation_num']\n",
    "national_valuations = national_valuations.sum().sort_values(ascending=False).reset_index()\n",
    "\n",
    "# Print the top 15 values of the DataFrame.\n",
    "national_valuations.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JM0yLhuXeXb4"
   },
   "source": [
    "### Filter out top 4 outlying countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this grouped and summed data to plot a barplot. However, to meet the needs of your stakeholder, you must first remove the United States, China, India, and the United Kingdom. Remove these countries from `national_valuations` and reassign the results to a variable called `national_valuations_no_big4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94223263"
   },
   "outputs": [],
   "source": [
    "# Remove outlying countries\n",
    "national_valuations_no_big4 = national_valuations.iloc[4:, :]\n",
    "national_valuations_no_big4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create barplot for top 20 non-big-4 countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the data is ready to reveal the top 20 non-big-4 countries with the highest total company valuations. Use seaborn's [`barplot()`](https://seaborn.pydata.org/generated/seaborn.barplot.html) function to create a plot showing national valuation on one axis and country on the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cd359c4"
   },
   "outputs": [],
   "source": [
    "# Create a barplot to compare the top 20 countries with highest company valuations.\n",
    "sns.barplot(data=national_valuations_no_big4.head(20),\n",
    "            y='Country/Region',\n",
    "            x='valuation_num')\n",
    "plt.title('Top 20 non-big-4 countries by total company valuation')\n",
    "\n",
    "# Show the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aca44e9f"
   },
   "source": [
    "### Plot maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6875df3e"
   },
   "source": [
    "Your investor has also asked for a global valuation map of all countries except `United States`, `China`, `India`, and `United Kingdom` (a.k.a. \"big-four countries\").\n",
    "\n",
    "You have learned about using [`scatter_geo()`](https://plotly.com/python-api-reference/generated/plotly.express.scatter_geo) from the `plotly.express` library to create plot data on a map. Create a `scatter_geo()` plot that depicts the total valuations of each non-big-four country on a world map, where each valuation is shown as a circle on the map, and the size of the circle is proportional to that country's summed valuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5089cf7"
   },
   "outputs": [],
   "source": [
    "# Plot the sum of valuations per country.\n",
    "\n",
    "data = national_valuations_no_big4\n",
    "\n",
    "px.scatter_geo(data, \n",
    "               locations='Country/Region', \n",
    "               size='valuation_num', \n",
    "               locationmode='country names', \n",
    "               color='Country/Region',\n",
    "               title='Total company valuations by country (non-big-four)')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1D-SVQBZbnniSdt931Vd2drfvP_D0FNCC",
     "timestamp": 1661469989747
    },
    {
     "file_id": "1OZW8XgxaFvstKFchHbudTfA5IVDxThz0",
     "timestamp": 1661403750705
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
